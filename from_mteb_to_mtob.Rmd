```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, warning=FALSE)
```

```{r message=FALSE, warning=FALSE}
library(effects)
library(emmeans)
library(ggpubr)
library(lme4)
library(skimr)
library(stringr)
library(tidyverse)
```

```{txt name}
Альберт Корнилов, Василиса Колесник
```

# From MTEB to MTOB: Retrieval-Augmented Classification for Descriptive Grammars

Данные взяты из исследования (Kornilov & Shavrina, 2024): [From MTEB to MTOB: Retrieval-Augmented Classification for Descriptive Grammars](https://arxiv.org/pdf/2411.15577).

Источник данных: репозиторий [from-MTEB-to-MTOB](https://github.com/al-the-eigenvalue/from-MTEB-to-MTOB/tree/main).

Статья (Kornilov & Shavrina, 2024) исследует способность больших языковых моделей (LLM) извлекать данные о языках мира из их описательных грамматик. Один из бенчмарков, представленных в статье, состоит из 148 грамматик, для каждой из которых размечены следующие типологические характеристики:

1. Доминантный порядок слов в монотранзитивной конструкции (WALS 81A – Order of Subject, Object, and Verb. SOV/SVO/VSO и т.д.)
2. Стратегия маркирования стандартного отрицания (GB107 – “Can standard negation be marked by an affix, clitic or modification of the verb?”). 1 = отрицание может маркироваться любой модификацией глагола, 0 = не может 
3. Cтратегии маркирования полярных вопросов (GB257, GB260, GB262, GB263, GB264, GB286, GB291: Interrogative intonation only, Interrogative word order, Clause-initial question particle, Clause-medial question particle, Clause-final question particle, Interrogative verb morphology, Tone). 7 бинарных признаков. Для каждого признака/стратегии 1, если она может использоваться для маркирования полярных вопросов, и 0, если не может.

В работе тестируется GPT-4o в четырёх конфигурациях Retrieval Augmented Generation (RAG):

± Ранжирование контекста (реранкер)

± Метод цепочки рассуждений (Chain-of-Thought, CoT)

![](https://private-user-images.githubusercontent.com/72064593/396036935-f3e322c2-0a6e-4694-8e47-ed8bebe26624.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTA3ODAyNTAsIm5iZiI6MTc1MDc3OTk1MCwicGF0aCI6Ii83MjA2NDU5My8zOTYwMzY5MzUtZjNlMzIyYzItMGE2ZS00Njk0LThlNDctZWQ4YmViZTI2NjI0LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA2MjQlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNjI0VDE1NDU1MFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWM0MTY0MjVlYWQyMGZkOTY0NmJkNGUzZjM3NzhjMzk5NTk3OTEzZjRhZDNkOTk5NTMyM2QyZjZhZDQ3ZGQ4YjImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.dHKoqLBSnMRi7I0VlvpRfqZAZAKie7OZDCsoNP2bz44)

## Цель проекта:

Выявить статистически значимые факторы, влияющие на точность (accuracy) предсказаний GPT-4o для характеристик 1–3 (точность = правильная vs. неправильная классификация).

Для каждого фактора (макроареал, кол-во страниц в грамматике, год публикации, конфигурация RAG-системы):

H0: фактор не имеет связи с качеством предсказаний GPT-4o;

H1: фактор имеет связь с качеством предсказаний GPT-4o.

Уровень значимости, который мы будем использовать: 0.05.

## Гипотезы и обоснование их проверки

Исследуем зависимость accuracy от следующих переменных:

**1. Конфигурация RAG**

Почему? - Это основная экспериментальная переменная. Проверяем, повышают ли реранкинг и Chain-of-Thought (опциональные элементы в конфигурации) качество системы.

**2. Объём грамматики (кол-во страниц)**

Почему? - Есть гипотеза, что длина документа влияет на эффективность поиска. 
Мало страниц → ключевые детали могут быть опущены или описаны слишком кратко.
Много страниц → релевантная информация может "потеряться" в большом объёме текста ("иголка в стоге сена"), что затруднит её извлечение RAG-модулем.

**3. Год издания грамматики**

Почему? - Лингвистическая терминология и стиль описания меняются со временем. В грамматиках XX века могут использоваться иные термины, чем в современных.

**4. Макроареал языка**

Почему? - Из-за разных лингвистических традиций описания языков разных регионов также могут варьироваться термины и способ описания лингвистических феноменов.

Пример вариативности: в разных грамматиках порядок слов Subject-Object-Verb может быть описан как

- Subject-Object-Verb

- SOV

- S-O-V

- AOV

- A-O-V

- head-final

- predicate-final

- verb-final

## Датасет

```{r read_data}
grammars <- read.csv("https://raw.githubusercontent.com/al-the-eigenvalue/from-MTEB-to-MTOB/refs/heads/main/ground_truth_rag.csv")
glimpse(grammars)
```
```{r skim}
skim(grammars)
```

Для составления выборки языков в статье был использован метод Genus-Macroarea, предложенный (Miestamo et al., 2016), чтобы избежать искажений (излишней репрезентации какой-либо генеалогической категории или географического положения):

1) только один язык на каждый генус;

2) стратификация по макроареалам в таких же пропорциях, какие представлены в генеральной совокупности (в реальном мире).

Была использована реализация этого метода, представленная (Cheveleva, 2023):

1) только один язык на каждый генус;

2) стратификация по макроареалам в таких же пропорциях, как в WALS;

3) для каждого генуса автоматически выбирается язык, у которого грамматика на английском языке с самым большим количеством страниц в Glottolog.

## Анализ данных

Распределение языков по макроареалам:


```{r macroarea_count}
grammars %>%
  count(Macroarea)
```

```{r macroarea_hist}
ggplot(data=grammars) +
  geom_bar(aes(x=Macroarea, fill=Macroarea))
```

Препроцессинг для года написания грамматики.
Необходимо трансформировать не подходящие под числовой формат данные следующим образом:

1992 [1930] -> 1992

1933-1938 -> 1938

no date -> NA

```{r preprocess_year}
preprocess_year <- function(year_string) {
  year_string <- str_remove(year_string, "\\s*\\[.*?\\]")

  if (grepl("-", year_string)) {
    year_string <- str_split(year_string, "-")[[1]][2]
  }
  year_numeric <- as.numeric(year_string)

  return(year_numeric)
}

grammars$Year <- sapply(grammars$Year, preprocess_year)
```

Выборка охватывает 120 лет лингвистических исследований. Грамматик, написанных до 1960 года, в выборке меньше всего. На графике можно наблюдать рост количества грамматик с 1980 года по настоящее время. Большинство грамматик были написаны в XXI веке:

```{r hist_year}
hist(
  grammars$Year,
  main=paste("Распределение года написания грамматики"),
  xlab="Год написания грамматики",
  ylab="Количество грамматик"
)
```
На графике плотности распределения года грамматики по макроареалам мы можем наблюдать, что пик (самая высокая плотность) для количества грамматик находится в XXI веке для всех макроареалов, кроме Австралии, у которой пик приходится на ~1990. Самый поздний пик (~2015) у грамматик языков Африки. 

```{r geomdensity_year_macroarea}
ggplot(data=grammars, aes(x=Year, group=Macroarea, fill=Macroarea)) +
    geom_density(alpha=0.4) +
    labs(
      x="Год написания грамматики",
      y="Плотность",
      fill="Макроареал",
      title="Год написания грамматики по макроареалам"
    )
```
На гистограмме, которая показывает распределение количества страниц в грамматике, можно наблюдать, что большая часть грамматик имеет 400-600 страниц. Также в выборке есть выбросы, у которых > 1500 страниц.

```{r hist_pages}
hist(
  grammars$Pages,
  main=paste("Распределение количества страниц в грамматике"),
  xlab="Количество страниц в грамматике",
  ylab="Количество грамматик"
)
```
Пик (самая высокая плотность) для количества страниц для всех макроареалов приходится на 500-600 страниц, кроме грамматик австронезийских языков и языков Папуа — Новой Гвинеи (макроареал Папунезия), где два пика: один на ~240 страниц, другой на ~520. Все грамматики языков Австралии (которых меньше всего в выборке, 9) попали в интервал между 250 и 1000 страниц (более "узкая" кривая плотности, чем у остальных макроареалов).

```{r hist_year_pages}
ggplot(data=grammars, aes(x=Pages, group=Macroarea, fill=Macroarea)) +
    geom_density(alpha=0.4) +
    labs(
      x="Количество страниц в грамматике",
      y="Плотность",
      fill="Макроареал",
      title="Количество страниц в грамматике по макроареалам"
    )
```
Между годом написания грамматики и количеством страниц не наблюдается сильной линейной зависимости, поэтому мы учитываем оба этих предиктора при построении итоговой модели (иначе потребовалось бы удалить один из них, чтобы устранить коллинеарность).

```{r scatter_plot}
ggplot(data=grammars, aes(x=Year, y=Pages)) +
  geom_point(alpha=0.3, colour="blue") +
  geom_smooth(method="lm", formula= y~x, colour="blue") +
  xlab("Год написания грамматики") +
  ylab("Количество страниц в грамматике")
```

## Подготовка данных для модели

Полный датасет с результатами предсказаний GPT-4o:

```{r read_all_data}
rag_results <- read.csv("https://raw.githubusercontent.com/al-the-eigenvalue/from-MTEB-to-MTOB/refs/heads/main/from_mteb_to_mtob.csv")
rag_results$Year <- sapply(rag_results$Year, preprocess_year)
glimpse(rag_results)
```

В датасете с результатами RAG 5328 строк. это исходный датасет грамматик, размноженный в 36 раз:

- 9 лингвистических характеристик (1 для порядка слов + 1 для стратегии маркирования отрицания + 7 стратегий маркирования полярных вопросов) для каждой грамматики

- 4 конфигурации RAG (± реранкер, ± Chain-of-Thought) для каждой комбинации грамматики и характеристики.

Для построения модели потребуются следующие столбцы датасета:

- **ISO.639.3**: код языка ISO 639 как уникальный идентификатор грамматики. Он необходим для того, чтобы учитывать влияние индивидуальной грамматики как случайный эффект;

- **Feature**: лингвистическая характеристика. Она также будет рассмотрена как случайный эффект: мы взяли 9 характеристик не как фиксированный набор, а как сэмпл из всех существующих в WALS и Grambank;

- **Macroarea**: макроареал языка;

- **Year**: год публикации грамматики;

- **Pages**: количество страниц в грамматике;

- **Reranker**: 1, если в конфигурации использовался реранкер, и 0, если не использовался;

- **CoT**: 1, если в промпте для GPT-4o использовался метод цепочки рассуждений (Chain-of-Thought), и 0, если не использовался;

- **Result**: таргет-переменная. 1, если GPT-4o предсказала значение лингвистической характеристики правильно, и 0, если неправильно.

Макроареал, лингвистическая характеристика и код языка ISO 639 - категориальные переменные, поэтому их необходимо преобразовать в факторы:

```{r factors}
rag_results$ISO.639.3 <- factor(rag_results$ISO.639.3)
rag_results$Feature <- factor(rag_results$Feature)
rag_results$Macroarea <- factor(rag_results$Macroarea)
```

Во всех остальных столбцах, кроме ISO.639.3, Feature и Macroarea, находятся числовые данные. Все числовые переменные бинарные, кроме года публикации грамматики и количества страниц, поэтому необходимо нормализовать только столбцы Year и Pages:

```{r normalization}
rag_results$Year_Scaled <- scale(rag_results$Year)
rag_results$Pages_Scaled <- scale(rag_results$Pages)
```

## Модель

Так как предикторов больше двух, а таргет-переменная бинарная, в качестве модели выбираем бинарную логистическую регрессию.

Так как ISO.639.3 не вложена в Feature, и Feature не вложена в ISO.639.3 (для каждого языка есть все характеристики, и для каждой характеристики есть все языки), случайные эффекты в модели будут представлены как (1 | ISO.639.3) + (1 | Feature).
(источник: https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified)

Кроме влияния наличия/отсутствия реранкера и наличия/отсутствия Chain-of-Thought на результат по отдельности, проанализируем также и взаимодействие между ними. Все вместе можно записать как ```Reranker + CoT + Reranker:CoT``` или ```Reranker*CoT``` (источник: https://stackoverflow.com/questions/40567421/asterisk-vs-colon-in-r-formulas)

```{r logreg}
model <- glmer(
  Result ~ Reranker + CoT + Reranker:CoT + Year_Scaled + Pages_Scaled + Macroarea + (1 | ISO.639.3) + (1 | Feature),
  data=rag_results,
  family=binomial,
  control=glmerControl(optimizer="bobyqa")
)
```

Summary модели:

```{r summary}
summary(model)
```
## Анализ и интерпретация

### Фиксированные эффекты

**CoT (Chain-of-Thought):** β = 0.22396, p-value = 0.0477. β > 0, и это означает, что использование Chain-of-Thought увеличивает вероятность правильного ответа. Наличие/отсутствие Chain-of-Thought статистически значимо (p-value = 0.0477). β = 0.22396 соответствует увеличению log-odds в 0.22396, т.е. odds в exp(0.22396) ≈ 1.25 раз (на 25%).

источник для интерпретации β: https://www.sthda.com/english/articles/36-classification-methods-essentials/151-logistic-regression-essentials-in-r/

**Reranker:** Эффект незначим (β = 0.12897, p-value = 0.2487). Использование реранкера само по себе не приводит к значимому улучшению результатов.

**Взаимодействие Reranker и CoT:** Эффект незначим (β = -0.05119, p-value = 0.7517) => совместное использование реранкера и CoT не дает дополнительного эффекта сверх того, что ожидается от простого сложения их индивидуальных эффектов.

**Год издания:** Положительный значимый эффект (β = 0.21205, p-value = 0.0291). Более новые книги ассоциированы с увеличением вероятности правильного ответа. Так как переменная масштабирована: при увеличении года издания на одно стандартное отклонение log-odds правильного ответа увеличивается на 0.21205 (odds увеличивается в exp(0.21205) ≈ на 24%).

(scale трансформирует данные так, чтобы среднее было 0, а стандартное отклонение было 1 https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/scale, поэтому увеличение значения нормализованного предиктора на 1 = увеличение значения предиктора на одно стандартное отклонение)

**Количество страниц:** Отрицательный значимый эффект (β = -0.21229, p = 0.0298). Для грамматик с большим кол-вом страниц уменьшается вероятность правильного ответа. Увеличение количества страниц на одно стандартное отклонение уменьшает log-odds на 0.21229 (odds уменьшается в exp(0.21229) ≈ на 24%).

**Макроареал:** Ни один из макроареалов не показал статистически значимого эффекта по сравнению с бейзлайном (Африка, так как она не указана в summary модели). Все p-значения > 0.05. Это означает, что макроареал языка не влияет на эффективность модели.

### Случайные эффекты

**ISO.639.3:** Дисперсия = 0.806 (т.к. стандартное отклонение = 0.898, дисперсия = 0.898^2). Указывает на то, что между языками существуют различия в сложности или в качестве описания в грамматике, которые влияют на результат.

**Лингвистическая характеристика:** Дисперсия = 1.264 (т.к. стандартное отклонение = 1.1244). Значительная вариация между вопросами, что ожидаемо — некоторые вопросы сложнее других.

### Выводы

- Лучшая конфигурация: Chain-of-Thought (использование реранкера не значимо).

- Грамматики: лучше результат для новых и с меньшим количеством страниц.

- Макроареал не имеет значения.

- Учет случайных эффектов (язык и лингвистическая характеристика) важен, так как они вносят существенную изменчивость.

### Post-hoc тест для конфигураций RAG

Для попарного сравнения конфигураций RAG используем post-hoc тест TukeyHSD:

```{r posthoc}
config_emmeans <- emmeans(
  model, 
  ~ Reranker * CoT,
  at=list(Reranker=c(0, 1), CoT=c(0, 1))
)

pairs(config_emmeans, adjust="tukey")
```
Единственное статистически значимое различие обнаружено между бейзлайном (Reranker = 0, CoT = 0) и той конфигурацией, где используются и реранкер, и Chain-of-Thought: p-value = 0.0412. 

Для Reranker = 0 CoT = 1 статистически значимого различия с бейзлайном не оказалось (p-value = 0.1955), несмотря на то, что в самой модели CoT был статистически значимым с p-value = 0.0477.

Возможная интерпретация:

Самый оптимальный вариант - использовать при предсказании лингвистических характеристик по грамматикам и Chain-of-Thought, и реранкер. При ограниченных вычислительных ресурсах использовать только Chain-of-Thought.
